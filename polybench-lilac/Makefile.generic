RUN_TIMEOUT?=7200 # 2 hours.
ROOT_DIR=/scratch/yc0769/llvm14-tulip/susan-v9
CUDAFE=/u/NAS_SCRATCH/yc0769/xstack/xstack-installs/TulipOoT
LLVM18=/u/NAS_SCRATCH/yc0769/xstack/xstack-installs/polygeist-llvm-install
POLYGEIST=/u/NAS_SCRATCH/yc0769/xstack/xstack-installs/polygeist-install
NOELLE=$ROOT_DIR/noelle/install
SPLENDID_CPU=/scratch/ah7226/llvm-install-tulip/bin/splendid
SPLENDID_GPU=/u/NAS_SCRATCH/yc0769/xstack/llvm-install-debug/bin/splendid
SPLENDID_ACC=/u/NAS_SCRATCH/yc0769/xstack/llvm-install-openacc/bin/splendid
SPLENDID_LOC=/u/NAS_SCRATCH/yc0769/xstack/llvm-install-openacc/bin/splendid

# LLM Transformation settings
LLM_TRANSFORM_DIR=../LLMTransformation
LLM_TRANSFORM_SCRIPT=$(LLM_TRANSFORM_DIR)/entry.py
LLM_TRANSFORM_OUTPUT_DIR=llm_output
# Set this to your OpenAI API key or export as environment variable
OPENAI_API_KEY?=$(shell echo $$OPENAI_API_KEY)
LLM_TRANSFORMATIONS?= function_order magic_number_extraction expression_breakup variable_replacement variable_elimination  parenthesis_cleanup comment_generation    
# magic_number_extraction function_order comment_generation variable_replacement magic_number_extraction parenthesis_cleanup variable_elimination expression_breakup
# Dynamically checks for transformation outputs in reverse order (final to first)
#ADDITIONAL_PASSES+=-O1
#SPLENDID_CPU=splendid
#SPLENDID_LOC=splendid
#SPLENDID_GPU=splendid
#SPLENDID_ACC=splendid


nvtarget.exe: #${BMARK}_cpu.cbe.c
	clang -g -fopenmp -fopenmp-cuda-mode -Rpass=openmp-opt -Rpass-analysis=openmp-opt -Rpass-missed=openmp-opt -fopenmp-assume-no-thread-state -fopenmp-assume-no-nested-parallelism --offload-arch=native ${BMARK}_gpu.c -O3 -c -o ${BMARK}_nvtarget.o
	clang -g --offload-link ${LLVM_LIBS_DIR}/libomptarget.so ${LLVM_LIBS_DIR}/libomp.so ${BMARK}_nvtarget.o -O3 -lm -o $@ -foffload-lto -lomptarget.devicertl

nvtarget_noelle.exe: #${BMARK}_cpu.cbe.c
	clang -g -fopenmp -fopenmp-cuda-mode -Rpass=openmp-opt -Rpass-analysis=openmp-opt -Rpass-missed=openmp-opt -fopenmp-assume-no-thread-state -fopenmp-assume-no-nested-parallelism --offload-arch=native ${BMARK}_gpu_noelle.c -O3 -c -o ${BMARK}_nvtarget.o
	clang -g --offload-link ${LLVM_LIBS_DIR}/libomptarget.so ${LLVM_LIBS_DIR}/libomp.so ${BMARK}_nvtarget.o -O3 -lm -o $@ -foffload-lto -lomptarget.devicertl

amdtarget.exe: #${BMARK}_cpu.cbe.c
	clang -fopenmp -fopenmp-targets=amdgcn-amd-amdhsa -Xopenmp-target=amdgcn-amd-amdhsa -march=gfx90a --rocm-path=/opt/rocm-5.4.2/ -fopenmp-cuda-mode -Rpass=openmp-opt -Rpass-analysis=openmp-opt -Rpass-missed=openmp-opt -fopenmp-assume-no-thread-state -fopenmp-assume-no-nested-parallelism ${BMARK}_gpu.c -O3 -c -o ${BMARK}_amdtarget.o
	clang --offload-link $(FLAGS) ${LLVM_LIBS_DIR}/libomp.so ${LLVM_LIBS_DIR}/libomptarget.so ${BMARK}_amdtarget.o ${LLVM_LIBS_DIR}/libomptarget.devicertl.a -O3 -o $@

amdtarget_noelle.exe: #${BMARK}_cpu.cbe.c
	clang -fopenmp -fopenmp-targets=amdgcn-amd-amdhsa -Xopenmp-target=amdgcn-amd-amdhsa -march=gfx90a --rocm-path=/opt/rocm-5.4.2/ -fopenmp-cuda-mode -Rpass=openmp-opt -Rpass-analysis=openmp-opt -Rpass-missed=openmp-opt -fopenmp-assume-no-thread-state -fopenmp-assume-no-nested-parallelism ${BMARK}_gpu_noelle.c -O3 -c -o ${BMARK}_amdtarget.o
	clang --offload-link $(FLAGS) ${LLVM_LIBS_DIR}/libomp.so ${LLVM_LIBS_DIR}/libomptarget.so ${BMARK}_amdtarget.o ${LLVM_LIBS_DIR}/libomptarget.devicertl.a -O3 -o $@

openacc.gpu.exe:
	nvc -acc=gpu -gpu=cc70 -Minfo=accel -O3 ${BMARK}_openacc.c -o $@

openacc.cpu.exe:
	nvc -acc=multicore -Minfo=accel -O3 ${BMARK}_openacc.c -o $@

nvhpc.gpu.noelle.exe:
	nvc -mp=gpu -gpu=cc70 -Minfo=accel -Mneginfo -O4 -fast ${BMARK}_gpu_noelle.nvc.c -o $@

nvhpc.gpu.exe:
	nvc -mp=gpu -gpu=cc70 -Minfo=accel -Mneginfo -O4 -fast ${BMARK}_gpu.nvc.c -o $@

nvhpc.cpu.noelle.exe:
	nvc -mp=multicore -Minfo=accel -O4 -fast ${BMARK}_gpu_noelle.nvc.c -o $@

nvhpc.cpu.exe:
	nvc -mp=multicore -Minfo=accel -O4 -fast ${BMARK}_gpu.nvc.c -o $@

manual.clang.amd.exe: ${BMARK}_amd_manual.c
	clang -fopenmp -fopenmp-targets=amdgcn-amd-amdhsa -Xopenmp-target=amdgcn-amd-amdhsa -march=gfx90a --rocm-path=/opt/rocm-5.4.2/ -fopenmp-cuda-mode -Rpass=openmp-opt -Rpass-analysis=openmp-opt -Rpass-missed=openmp-opt -fopenmp-assume-no-thread-state -fopenmp-assume-no-nested-parallelism ${BMARK}_amd_manual.c -O3 -c -o ${BMARK}_amdtarget_m.o
	clang --offload-link $(FLAGS) ${LLVM_LIBS_DIR}/libomp.so ${LLVM_LIBS_DIR}/libomptarget.so ${BMARK}_amdtarget_m.o ${LLVM_LIBS_DIR}/libomptarget.devicertl.a -O3 -o $@

manual.clang.gpu.exe: ${BMARK}_gpu_noelle_manual.c
	clang -g -fopenmp -fopenmp-cuda-mode -Rpass=openmp-opt -Rpass-analysis=openmp-opt -Rpass-missed=openmp-opt -fopenmp-assume-no-thread-state -fopenmp-assume-no-nested-parallelism --offload-arch=native ${BMARK}_gpu_noelle_manual.c -O3 -c -o ${BMARK}_nvtarget_manual.o
	clang -g --offload-link ${LLVM_LIBS_DIR}/libomptarget.so ${LLVM_LIBS_DIR}/libomp.so ${BMARK}_nvtarget_manual.o -O3 -lm -o $@ -foffload-lto -lomptarget.devicertl

manual.nvc.gpu.exe: ${BMARK}_gpu_noelle_manual.c
	nvc -mp=gpu -gpu=cc70 -Minfo=accel -Mneginfo -O4 -fast ${BMARK}_gpu_noelle_manual.c -o $@

manual.clang.cpu.exe: ${BMARK}_cpu_noelle_manual.c
	clang -fopenmp -O3 $(FLAGS) $< -o $@

manual.gcc.cpu.exe: ${BMARK}_cpu_noelle_manual.c
	gcc -fopenmp -O3 $(FLAGS) $< -o $@

%.ll: ${BMARK}.cu
	clang -Xclang -disable-O0-optnone -S -emit-llvm -g $<

${BMARK}_linked.bc: ${BMARK}-cuda-nvptx64-nvidia-cuda-sm_20.ll ${BMARK}.ll
	llvm-link-cudafe ${BMARK}-cuda-nvptx64-nvidia-cuda-sm_20.ll ${BMARK}.ll -o ${BMARK}_linked.bc

${BMARK}_cpu.bc: ${BMARK}_linked.bc
	#opt -load ${CUDAFE}/build/MergeKernel/libLLVMCudaFE.so -merge-kernel ${BMARK}_linked.bc -o ${BMARK}_cpu.bc 2> debug_cudafe
	opt -load ${CUDAFE}/build/MergeKernel/libLLVMCudaFE.so -merge-kernel -mem2reg -indvars -dce  ${ADDITIONAL_PASSES} ${BMARK}_linked.bc -o ${BMARK}_cpu.bc 2> debug_cudafe

${BMARK}_openacc.c: ${BMARK}_cpu.bc
	$(SPLENDID_ACC) $< 2> debug
	mv ${BMARK}_cpu.cbe.c $@

${BMARK}_cpu.c: ${BMARK}_cpu.bc
	$(SPLENDID_CPU) $< 2> debug
	cp ${BMARK}_cpu.cbe.c $@

# LLM Transformation targets
${BMARK}_cpu_llm.c: ${BMARK}_cpu.c
	@echo "Applying LLM transformations to ${BMARK}_cpu.c..."
	@if [ -z "$(OPENAI_API_KEY)" ] && ! grep -q '"api_key"[[:space:]]*:' $(LLM_TRANSFORM_DIR)/config.json 2>/dev/null; then \
		echo "Warning: no OPENAI_API_KEY and no api_key in config.json. Copying original file without transformation..."; \
		cp $< $@; \
	else \
		mkdir -p $(LLM_TRANSFORM_OUTPUT_DIR); \
		cd $(LLM_TRANSFORM_DIR) && python3 $(notdir $(LLM_TRANSFORM_SCRIPT)) $(abspath $<) \
			$(if $(OPENAI_API_KEY),--api-key "$(OPENAI_API_KEY)") \
			--config config.json \
			--transformations $(LLM_TRANSFORMATIONS) \
			--output-dir $(abspath $(LLM_TRANSFORM_OUTPUT_DIR)) \
			--verbose && \
		found_output=0; \
		for transform in $$(echo $(LLM_TRANSFORMATIONS) | tr ' ' '\n' | tac); do \
			if [ -f $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))/$${transform}_transformed.c ]; then \
				cp $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))/$${transform}_transformed.c $(abspath $@); \
				echo "LLM transformation successful ($${transform}), result saved to $@"; \
				found_output=1; \
				break; \
			fi; \
		done; \
		if [ $$found_output -eq 0 ]; then \
			echo "LLM transformation failed or produced no output, using original file"; \
			cp $(abspath $<) $(abspath $@); \
		fi; \
	fi

${BMARK}_gpu.c: ${BMARK}_cpu.bc
	$(SPLENDID_GPU) $< 2> debug
	cp ${BMARK}_cpu.cbe.c $@

${BMARK}_gpu_llm.c: ${BMARK}_gpu.c
	@echo "Applying LLM transformations to ${BMARK}_gpu.c..."
	@if [ -z "$(OPENAI_API_KEY)" ] && ! grep -q '"api_key"[[:space:]]*:' $(LLM_TRANSFORM_DIR)/config.json 2>/dev/null; then \
		echo "Warning: no OPENAI_API_KEY and no api_key in config.json. Copying original file without transformation..."; \
		cp $< $@; \
	else \
		mkdir -p $(LLM_TRANSFORM_OUTPUT_DIR); \
		cd $(LLM_TRANSFORM_DIR) && python3 $(notdir $(LLM_TRANSFORM_SCRIPT)) $(abspath $<) \
			$(if $(OPENAI_API_KEY),--api-key "$(OPENAI_API_KEY)") \
			--config config.json \
			--transformations $(LLM_TRANSFORMATIONS) \
			--output-dir $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))_gpu \
			--verbose && \
		found_output=0; \
		for transform in $$(echo $(LLM_TRANSFORMATIONS) | tr ' ' '\n' | tac); do \
			if [ -f $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))_gpu/$${transform}_transformed.c ]; then \
				cp $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))_gpu/$${transform}_transformed.c $(abspath $@); \
				echo "LLM transformation successful ($${transform}), result saved to $@"; \
				found_output=1; \
				break; \
			fi; \
		done; \
		if [ $$found_output -eq 0 ]; then \
			echo "LLM transformation failed or produced no output, using original file"; \
			cp $(abspath $<) $(abspath $@); \
		fi; \
	fi

${BMARK}_loc.c: ${BMARK}_cpu.bc
	opt ${LOC_PASSES} $< -o temp_loc.bc 
	$(SPLENDID_LOC) temp_loc.bc 2> debug
	cp temp_loc.cbe.c $@
#${BMARK}_pdg_embed.bc:${BMARK}_cpu.bc
#	noelle-load -PDGAnalysis -noelle-pdg-verbose=3 -noelle-pdg-embed ${BMARK}_svf.bc -o $@

${BMARK}_loopid.bc: ${BMARK}_cpu.bc
	noelle-meta-loop-embed $< -o $@
	noelle-parallel-load -load ${NOELLE}/lib/Planner.so -planner $@ -o $@ 


${BMARK}_reduced.bc: ${BMARK}_loopid.bc
	noelle-load -load ${NOELLE}/lib/ParallelizationTechnique.so -load ${NOELLE}/lib/DOALL.so -load ${NOELLE}/lib/DSWP.so -load ${NOELLE}/lib/Heuristics.so -load ${NOELLE}/lib/Parallelizer.so -load ${CUDAFE}/build/NoelleDOALL/libNoelleDOALL.so -noelle-verbose=3 -noelle-doall ${ADDITIONAL_PASSES}  $< -o $@

${BMARK}_cpu_noelle.c: ${BMARK}_reduced.bc
	$(SPLENDID_CPU) $< 2> debug
	mv ${BMARK}_reduced.cbe.c $@

${BMARK}_cpu_noelle_llm.c: ${BMARK}_cpu_noelle.c
	@echo "Applying LLM transformations to ${BMARK}_cpu_noelle.c..."
	@if [ -z "$(OPENAI_API_KEY)" ] && ! grep -q '"api_key"[[:space:]]*:' $(LLM_TRANSFORM_DIR)/config.json 2>/dev/null; then \
		echo "Warning: no OPENAI_API_KEY and no api_key in config.json. Copying original file without transformation..."; \
		cp $< $@; \
	else \
		mkdir -p $(LLM_TRANSFORM_OUTPUT_DIR); \
		cd $(LLM_TRANSFORM_DIR) && python3 $(notdir $(LLM_TRANSFORM_SCRIPT)) $(abspath $<) \
			$(if $(OPENAI_API_KEY),--api-key "$(OPENAI_API_KEY)") \
			--config config.json \
			--transformations $(LLM_TRANSFORMATIONS) \
			--output-dir $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))_cpu_noelle \
			--verbose && \
		found_output=0; \
		for transform in $$(echo $(LLM_TRANSFORMATIONS) | tr ' ' '\n' | tac); do \
			if [ -f $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))_cpu_noelle/$${transform}_transformed.c ]; then \
				cp $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))_cpu_noelle/$${transform}_transformed.c $(abspath $@); \
				echo "LLM transformation successful ($${transform}), result saved to $@"; \
				found_output=1; \
				break; \
			fi; \
		done; \
		if [ $$found_output -eq 0 ]; then \
			echo "LLM transformation failed or produced no output, using original file"; \
			cp $(abspath $<) $(abspath $@); \
		fi; \
	fi

${BMARK}_gpu_noelle.c: ${BMARK}_reduced.bc
	$(SPLENDID_GPU) $< 2> debug
	mv ${BMARK}_reduced.cbe.c $@

${BMARK}_gpu_noelle_llm.c: ${BMARK}_gpu_noelle.c
	@echo "Applying LLM transformations to ${BMARK}_gpu_noelle.c..."
	@if [ -z "$(OPENAI_API_KEY)" ] && ! grep -q '"api_key"[[:space:]]*:' $(LLM_TRANSFORM_DIR)/config.json 2>/dev/null; then \
		echo "Warning: no OPENAI_API_KEY and no api_key in config.json. Copying original file without transformation..."; \
		cp $< $@; \
	else \
		mkdir -p $(LLM_TRANSFORM_OUTPUT_DIR); \
		cd $(LLM_TRANSFORM_DIR) && python3 $(notdir $(LLM_TRANSFORM_SCRIPT)) $(abspath $<) \
			$(if $(OPENAI_API_KEY),--api-key "$(OPENAI_API_KEY)") \
			--config config.json \
			--transformations $(LLM_TRANSFORMATIONS) \
			--output-dir $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))_gpu_noelle \
			--verbose && \
		found_output=0; \
		for transform in $$(echo $(LLM_TRANSFORMATIONS) | tr ' ' '\n' | tac); do \
			if [ -f $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))_gpu_noelle/$${transform}_transformed.c ]; then \
				cp $(abspath $(LLM_TRANSFORM_OUTPUT_DIR))_gpu_noelle/$${transform}_transformed.c $(abspath $@); \
				echo "LLM transformation successful ($${transform}), result saved to $@"; \
				found_output=1; \
				break; \
			fi; \
		done; \
		if [ $$found_output -eq 0 ]; then \
			echo "LLM transformation failed or produced no output, using original file"; \
			cp $(abspath $<) $(abspath $@); \
		fi; \
	fi

${BMARK}.o: ${BMARK}.cu
	${POLYGEIST}/bin/cgeist --cuda-lower -cpuify="distribute" -raise-scf-to-affine --inner-serialize=1 -resource-dir=${LLVM18}/lib/clang/18/ -O3 $< -c -o $@

openmp.clang.exe: ${BMARK}_omp.c
	clang -fopenmp -O3 ${FLAGS} $< -o $@

openmp.gcc.exe: ${BMARK}_omp.c
	gcc -fopenmp -O3 $< -o $@ ${FLAGS} 

polygeist.exe: ${BMARK}.o
	clang -fopenmp -O3 ${FLAGS} $< -o $@

icx.exe: ${BMARK}_cpu.c
	icx -fopenmp -O3 $(FLAGS) $< -o $@

icx.noelle.exe: ${BMARK}_cpu_noelle.c
	icx -fopenmp -O3 $(FLAGS) $< -o $@

tulip.clang.noelle.exe: ${BMARK}_cpu_noelle.c
	clang -fopenmp -O3 $(FLAGS) $< -o $@

tulip.gcc.noelle.exe: ${BMARK}_cpu_noelle.c
	gcc -fopenmp -O3 $< -o $@ $(FLAGS)

tulip.clang.exe: ${BMARK}_cpu.c
	clang -fopenmp -O3 $(FLAGS) $< -o $@

tulip.gcc.exe: ${BMARK}_cpu.c
	gcc -fopenmp -O3 $< -o $@ $(FLAGS)

# LLM-transformed compilation targets
tulip.clang.llm.exe: ${BMARK}_cpu_llm.c
	clang -fopenmp -O3 $(FLAGS) $< -o $@

tulip.gcc.llm.exe: ${BMARK}_cpu_llm.c
	gcc -fopenmp -O3 $< -o $@ $(FLAGS)

tulip.clang.noelle.llm.exe: ${BMARK}_cpu_noelle_llm.c
	clang -fopenmp -O3 $(FLAGS) $< -o $@

tulip.gcc.noelle.llm.exe: ${BMARK}_cpu_noelle_llm.c
	gcc -fopenmp -O3 $< -o $@ $(FLAGS)

icx.llm.exe: ${BMARK}_cpu_llm.c
	icx -fopenmp -O3 $(FLAGS) $< -o $@

icx.noelle.llm.exe: ${BMARK}_cpu_noelle_llm.c
	icx -fopenmp -O3 $(FLAGS) $< -o $@

nvtarget.llm.exe: ${BMARK}_gpu_llm.c
	clang -g -fopenmp -fopenmp-cuda-mode -Rpass=openmp-opt -Rpass-analysis=openmp-opt -Rpass-missed=openmp-opt -fopenmp-assume-no-thread-state -fopenmp-assume-no-nested-parallelism --offload-arch=native $< -O3 -c -o ${BMARK}_nvtarget_llm.o
	clang -g --offload-link ${LLVM_LIBS_DIR}/libomptarget.so ${LLVM_LIBS_DIR}/libomp.so ${BMARK}_nvtarget_llm.o -O3 -lm -o $@ -foffload-lto -lomptarget.devicertl

nvtarget_noelle.llm.exe: ${BMARK}_gpu_noelle_llm.c
	clang -g -fopenmp -fopenmp-cuda-mode -Rpass=openmp-opt -Rpass-analysis=openmp-opt -Rpass-missed=openmp-opt -fopenmp-assume-no-thread-state -fopenmp-assume-no-nested-parallelism --offload-arch=native $< -O3 -c -o ${BMARK}_nvtarget_noelle_llm.o
	clang -g --offload-link ${LLVM_LIBS_DIR}/libomptarget.so ${LLVM_LIBS_DIR}/libomp.so ${BMARK}_nvtarget_noelle_llm.o -O3 -lm -o $@ -foffload-lto -lomptarget.devicertl

cpu.exe: ${BMARK}_reduced.bc
	clang -O3 -lm  $< -o $@

seq.exe: ${BMARK}.c
	clang -O3 -lm $< -o $@

cuda.exe: ${BMARK}.cu
	nvcc -O3 $< -o $@

run_seq: seq.exe
	regressions-watchdog $(RUN_TIMEOUT) seq.time ./seq.exe $(PERF_ARGS)

run_cuda: cuda.exe
	regressions-watchdog $(RUN_TIMEOUT) cuda.time ./cuda.exe $(PERF_ARGS)

run_nvidia: nvtarget.exe nvtarget_noelle.exe
	regressions-watchdog $(RUN_TIMEOUT) nvidia.time ./nvtarget.exe $(PERF_ARGS)
	regressions-watchdog $(RUN_TIMEOUT) nvidia.noelle.time ./nvtarget_noelle.exe $(PERF_ARGS)

run_amd: amdtarget.exe amdtarget_noelle.exe
	regressions-watchdog $(RUN_TIMEOUT) amd.time ./amdtarget.exe $(PERF_ARGS)
	regressions-watchdog $(RUN_TIMEOUT) amd.noelle.time ./amdtarget_noelle.exe $(PERF_ARGS)

run_polygeist: polygeist.exe
	regressions-watchdog $(RUN_TIMEOUT) polygeist.time ./polygeist.exe $(PERF_ARGS)

run_openacc: openacc.gpu.exe
	regressions-watchdog $(RUN_TIMEOUT) openacc.time ./openacc.gpu.exe $(PERF_ARGS)

run_icx: icx.exe icx.noelle.exe
	regressions-watchdog $(RUN_TIMEOUT) tulip.icx.time ./icx.exe $(PERF_ARGS)
	regressions-watchdog $(RUN_TIMEOUT) tulip.icx.noelle.time ./icx.noelle.exe $(PERF_ARGS)

run_tulip: tulip.clang.noelle.exe tulip.gcc.noelle.exe tulip.clang.exe tulip.gcc.exe 
	regressions-watchdog $(RUN_TIMEOUT) tulip.clang.time ./tulip.clang.exe $(PERF_ARGS) 
	regressions-watchdog $(RUN_TIMEOUT) tulip.gcc.time ./tulip.gcc.exe $(PERF_ARGS) 
	regressions-watchdog $(RUN_TIMEOUT) tulip.clang.noelle.time ./tulip.clang.noelle.exe $(PERF_ARGS) 
	regressions-watchdog $(RUN_TIMEOUT) tulip.gcc.noelle.time ./tulip.gcc.noelle.exe $(PERF_ARGS)

run_tulip_llm: tulip.clang.llm.exe tulip.gcc.llm.exe tulip.clang.noelle.llm.exe tulip.gcc.noelle.llm.exe
	regressions-watchdog $(RUN_TIMEOUT) tulip.clang.llm.time ./tulip.clang.llm.exe $(PERF_ARGS) 
	regressions-watchdog $(RUN_TIMEOUT) tulip.gcc.llm.time ./tulip.gcc.llm.exe $(PERF_ARGS) 
	regressions-watchdog $(RUN_TIMEOUT) tulip.clang.noelle.llm.time ./tulip.clang.noelle.llm.exe $(PERF_ARGS) 
	regressions-watchdog $(RUN_TIMEOUT) tulip.gcc.noelle.llm.time ./tulip.gcc.noelle.llm.exe $(PERF_ARGS)

run_icx_llm: icx.llm.exe icx.noelle.llm.exe
	regressions-watchdog $(RUN_TIMEOUT) tulip.icx.llm.time ./icx.llm.exe $(PERF_ARGS)
	regressions-watchdog $(RUN_TIMEOUT) tulip.icx.noelle.llm.time ./icx.noelle.llm.exe $(PERF_ARGS)

run_nvidia_llm: nvtarget.llm.exe nvtarget_noelle.llm.exe
	regressions-watchdog $(RUN_TIMEOUT) nvidia.llm.time ./nvtarget.llm.exe $(PERF_ARGS)
	regressions-watchdog $(RUN_TIMEOUT) nvidia.noelle.llm.time ./nvtarget_noelle.llm.exe $(PERF_ARGS) 

run_nvhpc: nvhpc.cpu.exe nvhpc.cpu.noelle.exe nvhpc.gpu.exe nvhpc.gpu.noelle.exe
	regressions-watchdog $(RUN_TIMEOUT) nvhpc.cpu.time ./nvhpc.cpu.exe $(PERF_ARGS)
	regressions-watchdog $(RUN_TIMEOUT) nvhpc.cpu.reduced.time ./nvhpc.cpu.noelle.exe $(PERF_ARGS)
	regressions-watchdog $(RUN_TIMEOUT) nvhpc.gpu.time ./nvhpc.gpu.exe $(PERF_ARGS)
	regressions-watchdog $(RUN_TIMEOUT) nvhpc.gpu.reduced.time ./nvhpc.gpu.noelle.exe $(PERF_ARGS)

run_manual:  manual.clang.cpu.exe manual.gcc.cpu.exe 
	regressions-watchdog $(RUN_TIMEOUT) manual.clang.cpu.time ./manual.clang.cpu.exe $(PERF_ARGS) 
	regressions-watchdog $(RUN_TIMEOUT) manual.gcc.cpu.time ./manual.gcc.cpu.exe $(PERF_ARGS) 

run_nvmanual: manual.clang.gpu.exe manual.nvc.gpu.exe
	regressions-watchdog $(RUN_TIMEOUT) manual.clang.gpu.time ./manual.clang.gpu.exe $(PERF_ARGS) 
	regressions-watchdog $(RUN_TIMEOUT) manual.nvc.gpu.time ./manual.nvc.gpu.exe $(PERF_ARGS) 

run_amdmanual: manual.clang.amd.exe 
	regressions-watchdog $(RUN_TIMEOUT) manual.clang.amd.time ./manual.clang.amd.exe $(PERF_ARGS) 

run_openmp: openmp.clang.exe  openmp.gcc.exe
	regressions-watchdog $(RUN_TIMEOUT) openmp.clang.time ./openmp.clang.exe $(PERF_ARGS) 
	regressions-watchdog $(RUN_TIMEOUT) openmp.gcc.time ./openmp.gcc.exe $(PERF_ARGS) 

# Convenience targets for LLM transformations
llm_transform: ${BMARK}_cpu_llm.c ${BMARK}_gpu_llm.c ${BMARK}_cpu_noelle_llm.c ${BMARK}_gpu_noelle_llm.c
	@echo "All LLM transformations completed"

llm_cpu_only: ${BMARK}_cpu_llm.c
	@echo "CPU LLM transformation completed"

llm_build: tulip.clang.llm.exe tulip.gcc.llm.exe
	@echo "LLM-transformed executables built"

llm_test: run_tulip_llm
	@echo "LLM-transformed executables tested"

# Show available LLM transformations
llm_info:
	@echo "Available LLM transformations:"
	@if [ -f $(LLM_TRANSFORM_SCRIPT) ]; then \
		cd $(LLM_TRANSFORM_DIR) && python3 $(notdir $(LLM_TRANSFORM_SCRIPT)) --list-transformations; \
	else \
		echo "LLM transformation script not found at $(LLM_TRANSFORM_SCRIPT)"; \
	fi

# Help target
help:
	@echo "LLM Transformation Makefile Targets:"
	@echo "  llm_transform    - Apply LLM transformations to all C files"
	@echo "  llm_cpu_only     - Apply LLM transformations to CPU-only files"
	@echo "  llm_build        - Build executables from LLM-transformed code"
	@echo "  llm_test         - Run tests with LLM-transformed executables"
	@echo "  llm_info         - Show available LLM transformations"
	@echo "  run_tulip_llm    - Run tulip with LLM-transformed code"
	@echo "  run_icx_llm      - Run ICX with LLM-transformed code"
	@echo "  run_nvidia_llm   - Run NVIDIA targets with LLM-transformed code"
	@echo ""
	@echo "Configuration variables:"
	@echo "  OPENAI_API_KEY        - OpenAI API key (required)"
	@echo "  LLM_TRANSFORMATIONS   - Space-separated list of transformations to apply"
	@echo "  LLM_TRANSFORM_OUTPUT_DIR - Output directory for LLM results"

clean_non_llm:
	rm -rf *.ll *.bc *.cbe.c *.exe debug *.o loopIDtoSrc.txt debug_cudafe *.log _loc.c ${BMARK}_cpu ${BMARK}_cpu_llm
	rm dictionary.json


clean:
	rm -rf *.ll *.bc *.cbe.c *.exe debug *.o loopIDtoSrc.txt debug_cudafe *.log _loc.c
	rm -rf *_llm.c $(LLM_TRANSFORM_OUTPUT_DIR)* *.time
	rm dictionary.json
